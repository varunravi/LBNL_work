{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import wget\n",
    "import re\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this to get data sets from Legacy Surveys\n",
    "### Specifies files from Tractor to download, pulls info on objects, gets fits cutouts from skyviewer using coordinates, writes csv file to have the same format as the training classifications.csv, writes csvfile containing object info from Tractor, returns object dictionaries\n",
    "### NOTE: The directories 'tractor_folders', 'tractor_fits' and 'fits_cutouts' must exist in the same folder as this notebook to run."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TRACTOR CATALOG INDEX\n",
    "\n",
    "idx - value -\n",
    "0     release\n",
    "1     brickid\n",
    "2     brickname\n",
    "3     objid\n",
    "6     ra\n",
    "7     dec\n",
    "17    g_flux\n",
    "18    r_flux\n",
    "20    z_flux\n",
    "65    g_nobs\n",
    "66    r_nobs\n",
    "68    z_nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluxToMag(f):\n",
    "    return (-2.5 * (np.log(f)/np.log(10.) - 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! NOT USING THIS VERSION ANYMORE !!!\n",
    "# - this one does cutouts last, but it's better to get a cutout after each object is pulled and then write csv\n",
    "#   files afterwards\n",
    "\n",
    "# t_folder = '000'-'359'\n",
    "# n_files = int or 'all'\n",
    "# n_objects = int or 'all'\n",
    "# min_passes = int\n",
    "\n",
    "# input above values. downloads files from Tractor, gets ra/dec of objects, downloads fits cutouts of those objects\n",
    "# using legacysurvey skyviewer. also generates csv file to match \"classifications.csv\" (from lens challlenge), and a\n",
    "# csv file containing all the information in the generated object dictionaries\n",
    "def download_Tractor(csvfile, objectcsvfile, t_folder='000', n_objects='all', min_passes=2, counter_init=0):\n",
    "    # download folder within tractor catalog from nersc portal, get html of folder webpage\n",
    "    print('downloading Tractor files...')\n",
    "    t_url = 'http://portal.nersc.gov/project/cosmo/data/legacysurvey/dr5/tractor/{}/'.format(t_folder)\n",
    "    foldername = '/Users/mac/Desktop/LBNL/DR5/tractor_folders/tractor_' + t_folder\n",
    "    t_folder_file = wget.download(t_url, foldername)\n",
    "    with open(t_folder_file) as wgetfile:\n",
    "        wgetdata = wgetfile.read()\n",
    "\n",
    "    # search html code for filename \n",
    "    prog = re.compile('(?<=\\.fits\">).{21}')\n",
    "    result = prog.findall(wgetdata)\n",
    "    \n",
    "    # create dictionaries for each object containing image, ra/dec, flux (mag), nobs (exposures)\n",
    "    objects = [] # list of object dictionaries\n",
    "    for f in result:\n",
    "        # open tractor file, get object info\n",
    "        print('opening file {}...'.format(f))\n",
    "        filelink = t_url + f\n",
    "        t_file = wget.download(filelink, '/Users/mac/Desktop/LBNL/DR5/tractor_fits/')\n",
    "        with fits.open(t_file) as fit:\n",
    "            filedata = fit[1].data\n",
    "        # go through objects\n",
    "        goodobj = 0\n",
    "        for i in range(filedata.shape[0]):\n",
    "            \n",
    "            # check if got enough\n",
    "            if len(objects) == n_objects:\n",
    "                print('\\nOKAY GOT ENOUGH BREAK NOWWWWW\\n')\n",
    "                break\n",
    "                \n",
    "            # determine coverage to see if object should be kept\n",
    "            nobs_g = filedata[i][65]\n",
    "            nobs_r = filedata[i][66]\n",
    "            nobs_z = filedata[i][68]\n",
    "            if nobs_g >= min_passes and nobs_r >= min_passes and nobs_z >= min_passes:\n",
    "                ra = filedata[i][6]\n",
    "                dec = filedata[i][7]\n",
    "                print('\\tgetting object at {} {}'.format(ra,dec))\n",
    "\n",
    "                image = 'not cut yet'\n",
    "                filename = 'not cut yet'\n",
    "                brickname = filedata[i][2]\n",
    "                objid = filedata[i][3]\n",
    "\n",
    "                flux_g = filedata[i][17]\n",
    "                mag_g = 0\n",
    "                if flux_g != 0:\n",
    "                    mag_g = fluxToMag(flux_g)\n",
    "\n",
    "                flux_r = filedata[i][18]\n",
    "                mag_r = 0\n",
    "                if flux_r != 0:\n",
    "                    mag_r = fluxToMag(flux_r)\n",
    "\n",
    "                flux_z = filedata[i][20]\n",
    "                mag_z = 0\n",
    "                if flux_z != 0:\n",
    "                    mag_z = fluxToMag(flux_z)\n",
    "\n",
    "                object_dict = {'image':image,'brickname':brickname,'objid':objid,'filename':'not cut yet','ra':ra,'dec':dec,'flux_g':flux_g,'flux_r':flux_r,'flux_z':flux_z,'mag_g':mag_g,'mag_r':mag_r,'mag_z':mag_z,'nobs_g':nobs_g,'nobs_r':nobs_r,'nobs_z':nobs_z}\n",
    "                objects.append(object_dict)    \n",
    "                goodobj += 1\n",
    "        print('got {} good objects from file {}'.format(goodobj, f))\n",
    "        if len(objects) == n_objects:\n",
    "            print('enough objects gathered.')\n",
    "            break\n",
    "            \n",
    "            \n",
    "            # this was to figure out the ACTUAL index, leaving here in case I need to search through catalog again\n",
    "#             print(object_dict)\n",
    "#             print(filedata[i])\n",
    "#             print('\\n')\n",
    "#             for j in range(len(filedata[i])):\n",
    "#                 try:\n",
    "#                     print('{}: flux={}, mag={}'.format(j, filedata[i][j], fluxToMag(filedata[i][j])))\n",
    "#                 except TypeError:\n",
    "#                     print('incorrect input type for fluxToMag function')\n",
    "#             print('\\n\\n\\n\\n')\n",
    "\n",
    "\n",
    "    # now create csv file to match fits file images, imitating the lensfinder challenge format\n",
    "    print('writing classification csv file...')\n",
    "    with open(csvfile+'_'+t_folder+'.csv', 'w') as myFile:  \n",
    "        # NOTE: can't get these to have double quotes (e.g. \"ID\") in the csv file. can only get none and \"\"\"ID\"\"\"\n",
    "        # not sure if this will affect how it works (lensfinder challenge csv headers have double quotes)\n",
    "        myFields = [\"ID\",\"is_lens\",\"Einstein_area\",\"numb_pix_lensed_image\",\"flux_lensed_image_in_sigma\"]\n",
    "        writer = csv.DictWriter(myFile, fieldnames=myFields)    \n",
    "        writer.writeheader()\n",
    "        counter=counter_init\n",
    "        for i in range(len(objects)):\n",
    "            # might want to change the ID for the training process if it makes it easier to iterate\n",
    "            ID = '{:06d}'.format(counter)\n",
    "            counter+=1\n",
    "            writer.writerow({\"ID\":ID,\"is_lens\":0,\"Einstein_area\":'nan',\"numb_pix_lensed_image\":'nan',\"flux_lensed_image_in_sigma\":'nan'})\n",
    "\n",
    "    # write csv file to contain information from object dictionaries\n",
    "    print('writing object info csv file...')\n",
    "    with open(objectcsvfile+'_'+t_folder+'.csv', 'w') as oFile:  \n",
    "        # omitting 'image' bc it's a lot to put in the csv file and we already have it\n",
    "        oFields = ['brickname','objid','filename','ra','dec','flux_g','flux_r','flux_z','mag_g','mag_r','mag_z','nobs_g','nobs_r','nobs_z']\n",
    "        writer = csv.DictWriter(oFile, fieldnames=oFields)    \n",
    "        writer.writeheader()\n",
    "        for o in objects:\n",
    "            writer.writerow({'brickname':o['brickname'],'objid':o['objid'],'filename':o['filename'],'ra':o['ra'],'dec':o['dec'],'flux_g':o['flux_g'],'flux_r':o['flux_r'],'flux_z':o['flux_z'],'mag_g':o['mag_g'],'mag_r':o['mag_r'],'mag_z':o['mag_z'],'nobs_g':o['nobs_g'],'nobs_r':o['nobs_r'],'nobs_z':o['nobs_z']})\n",
    "    \n",
    "    # get fits cutouts from ra/dec and add images to object dictionaries\n",
    "    print('getting fits cutouts from skyviewer...')\n",
    "    # try to break downloads into segments so they actually work\n",
    "    counter = counter_init\n",
    "    fails = 0\n",
    "    for o in objects:\n",
    "        # url specifies ra/dec as well as size (101), pixscale (0.262 is native) and layer (decals-dr5)\n",
    "        url = 'http://legacysurvey.org/viewer/fits-cutout?ra={:5f}&dec={:5f}&size=101&layer=decals-dr5&pixscale=0.262&bands=grz'.format(o['ra'], o['dec'])\n",
    "        # try to download the fits cutout from viewer\n",
    "        try:\n",
    "#             filename = urllib.request.urlretrieve(url, '/Users/mac/Desktop/LBNL/DR5/fits_cutouts/cutout_{:06d}.fits'.format(counter))\n",
    "            filename = wget.download(url, '/Users/mac/Desktop/LBNL/DR5/fits_cutouts/cutout_{:06d}.fits'.format(counter))\n",
    "            with fits.open(filename) as fit:\n",
    "                o['image'] = fit[0].data\n",
    "                if fails > 0:\n",
    "                    print('a fits file was just succesfully cut from the viewer after an error on a previous file. nice!')\n",
    "#         except:\n",
    "#             print('some error happened well gosh darn it what is this from? let\\'s just try and ignore it :)')\n",
    "#             # try it again if fails\n",
    "#             try:\n",
    "#                 filename = wget.download(url, '/Users/mac/Desktop/LBNL/DR5/fits_cutouts/cutout_{:06d}.fits'.format(counter))\n",
    "#                 with fits.open(filename) as fit:\n",
    "#                     o['image'] = fit[0].data\n",
    "#             except:\n",
    "#                 print('yeah twice in a row we gonna raise it')\n",
    "#                 raise\n",
    "        except:\n",
    "            fails += 1\n",
    "            print('some issue happened getting cutout_{:06d}\\n- object info -\\nra, dec = {}, {}\\nbrickname, objid = {}, {}'.format(counter, o['ra'], o['dec'], o['brickname'], o['objid']))\n",
    "            o['image'] = 'ERROR: failed to load image from viewer during fits cutout download'\n",
    "            if fails == 20:\n",
    "                print('20 fails. Raising error')\n",
    "                raise\n",
    "\n",
    "        o['filename'] = 'cutout_{:06d}.fits'.format(counter)\n",
    "        counter+=1 \n",
    "    \n",
    "    print('done.')\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = download_Tractor(csvfile='class_test', objectcsvfile='objectinfo', t_folder='000', n_objects=100, min_passes=4, counter_init=0)\n",
    "test2 = download_Tractor(csvfile='class_test', objectcsvfile='objectinfo', t_folder='001', n_objects=100, min_passes=4, counter_init=100)\n",
    "test3 = download_Tractor(csvfile='class_test', objectcsvfile='objectinfo', t_folder='002', n_objects=100, min_passes=4, counter_init=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! STILL NOT USING THIS VERSION - SWITCHED TO TERMINAL AND .PY FILE\n",
    "\n",
    "# NEW VERSION, TRYING TO FIX WHEN OBJECTS ARE SKIPPED\n",
    "# this version will continuously append to files and not do each step all at once, meaning each time an object is found we\n",
    "# will immediately try to get cutout and then disregard if we can't\n",
    "\n",
    "def download_Tractor2(csvfile, objectcsvfile, t_folder='000', n_objects='all', min_passes=2, counter_init=0):\n",
    "    \n",
    "    # download folder within tractor catalog from nersc portal, get html of folder webpage\n",
    "    print('downloading Tractor files...')\n",
    "    t_url = 'http://portal.nersc.gov/project/cosmo/data/legacysurvey/dr5/tractor/{}/'.format(t_folder)\n",
    "    foldername = '/Users/mac/Desktop/LBNL/DR5/tractor_folders/tractor_' + t_folder\n",
    "    t_folder_file = wget.download(t_url, foldername)\n",
    "    with open(t_folder_file) as wgetfile:\n",
    "        wgetdata = wgetfile.read()\n",
    "\n",
    "    # search html code for filenames \n",
    "    prog = re.compile('(?<=\\.fits\">).{21}')\n",
    "    result = prog.findall(wgetdata)\n",
    "    \n",
    "    # create dictionaries for each object containing image, ra/dec, flux (mag), nobs (exposures)\n",
    "    objects = [] # list of object dictionaries\n",
    "    counter = counter_init\n",
    "    total_fails = 0\n",
    "    \n",
    "    # iterate through tractor filenames found\n",
    "    for f in result:\n",
    "        \n",
    "        # open the file, get object info\n",
    "        print('opening file {}...'.format(f))\n",
    "        filelink = t_url + f\n",
    "        t_file = wget.download(filelink, '/Users/mac/Desktop/LBNL/DR5/tractor_fits/')\n",
    "        with fits.open(t_file) as fit:\n",
    "            filedata = fit[1].data\n",
    "\n",
    "        # go through objects in file\n",
    "        goodobj = 0\n",
    "        for i in range(filedata.shape[0]):\n",
    "            \n",
    "            # check if enough objects have already been added to the list\n",
    "            if len(objects) == n_objects:\n",
    "                break\n",
    "            # stop program if it gets stalled after a failure and can't continue to get fits\n",
    "            if total_fails == 15:\n",
    "                print('!!! failed to get cutout 15 times - quitting early with recovered objects !!!')\n",
    "                break\n",
    "#                 raise TimeoutError('actually, that was 15 total failures while getting fits cutouts - quitting program. Figure your shit out dude.')\n",
    "            \n",
    "            # determine coverage to see if the object should be kept\n",
    "            nobs_g = filedata[i][65]\n",
    "            nobs_r = filedata[i][66]\n",
    "            nobs_z = filedata[i][68]\n",
    "            if nobs_g >= min_passes and nobs_r >= min_passes and nobs_z >= min_passes:\n",
    "\n",
    "                # now see if we can get it from the viewer cutout\n",
    "                ra = filedata[i][6]\n",
    "                dec = filedata[i][7]\n",
    "                print('\\t attempting to get cutout for object at {} {}'.format(ra,dec))\n",
    "                url = 'http://legacysurvey.org/viewer/fits-cutout?ra={}&dec={}&size=101&layer=decals-dr5&pixscale=0.262&bands=grz'.format(ra, dec)\n",
    "                failed_attempts = 0\n",
    "                failed = False\n",
    "                retrieved = False\n",
    "                while failed == False and retrieved == False:\n",
    "                    # checks how many attempts have been made, moves onto next object if too many\n",
    "                    if failed_attempts == 50:\n",
    "                        failed = True\n",
    "                    try:\n",
    "                        filename = wget.download(url, '/Users/mac/Desktop/LBNL/DR5/fits_cutouts_{}/cutout_{:06d}.fits'.format(t_folder, counter))\n",
    "                        with fits.open(filename) as fit:\n",
    "                            image = fit[0].data\n",
    "                        retrieved = True\n",
    "                    except:\n",
    "                        failed_attempts += 1\n",
    "                        if failed_attempts % 10 == 0:\n",
    "                            print('\\t\\tfailed attempt {}'.format(failed_attempts))\n",
    "                        pass\n",
    "   \n",
    "                if failed:\n",
    "                    # don't update object list or counter\n",
    "                    total_fails += 1\n",
    "                    print('\\t\\tfailed to retrieve cutout for object - moving on to next object...')\n",
    "                \n",
    "                if retrieved:\n",
    "                    # get all remaining values needed for dictionary, update object list and counter\n",
    "                    filename = 'cutout_{:06d}'.format(counter)\n",
    "                    brickname = filedata[i][2]\n",
    "                    objid = filedata[i][3]\n",
    "                    flux_g = filedata[i][17]\n",
    "                    mag_g = 0\n",
    "                    if flux_g != 0:\n",
    "                        mag_g = fluxToMag(flux_g)\n",
    "                    flux_r = filedata[i][18]\n",
    "                    mag_r = 0\n",
    "                    if flux_r != 0:\n",
    "                        mag_r = fluxToMag(flux_r)\n",
    "                    flux_z = filedata[i][20]\n",
    "                    mag_z = 0\n",
    "                    if flux_z != 0:\n",
    "                        mag_z = fluxToMag(flux_z)\n",
    "\n",
    "                    object_dict = {'image':image,'brickname':brickname,'objid':objid,'filename':filename,'ra':ra,'dec':dec,'flux_g':flux_g,'flux_r':flux_r,'flux_z':flux_z,'mag_g':mag_g,'mag_r':mag_r,'mag_z':mag_z,'nobs_g':nobs_g,'nobs_r':nobs_r,'nobs_z':nobs_z}\n",
    "                    objects.append(object_dict)\n",
    "                    counter += 1\n",
    "                    goodobj += 1\n",
    "                    \n",
    "        print('got {} good objects from {}'.format(goodobj, f))\n",
    "        if len(objects) == n_objects:\n",
    "            print('enough objects gathered.')\n",
    "            break\n",
    "        if total_fails == 15:\n",
    "            break\n",
    "    \n",
    "    # check to make sure there were enough objects found in the folder of files\n",
    "    if len(objects) < n_objects:\n",
    "        print('\\tonly able to retrieve {} good objects from folder {}'.format(len(objects), t_folder))\n",
    "\n",
    "\n",
    "    # now create csv file to match fits file images, imitating the lensfinder challenge format\n",
    "    print('writing classification csv file...')\n",
    "    with open(csvfile+'_'+t_folder+'.csv', 'w') as myFile:  \n",
    "        # NOTE: can't get fields to have double quotes (e.g. \"ID\") in the csv file. can only get none and \"\"\"ID\"\"\"\n",
    "        # not sure if this will affect how it works (lensfinder challenge csv headers have double quotes)\n",
    "        myFields = [\"ID\",\"is_lens\",\"Einstein_area\",\"numb_pix_lensed_image\",\"flux_lensed_image_in_sigma\"]\n",
    "        writer = csv.DictWriter(myFile, fieldnames=myFields)    \n",
    "        writer.writeheader()\n",
    "        counter=counter_init\n",
    "        for i in range(len(objects)):\n",
    "            # might want to change the ID for the training process if it makes it easier to iterate\n",
    "            ID = '{:06d}'.format(counter)\n",
    "            counter+=1\n",
    "            writer.writerow({\"ID\":ID,\"is_lens\":0,\"Einstein_area\":'nan',\"numb_pix_lensed_image\":'nan',\"flux_lensed_image_in_sigma\":'nan'})\n",
    "\n",
    "            \n",
    "    # write csv file to contain information from object dictionaries\n",
    "    print('writing object info csv file...')\n",
    "    with open(objectcsvfile+'_'+t_folder+'.csv', 'w') as oFile:  \n",
    "        # omitting 'image' bc it's a lot to put in the csv file and we already have it\n",
    "        oFields = ['brickname','objid','filename','ra','dec','flux_g','flux_r','flux_z','mag_g','mag_r','mag_z','nobs_g','nobs_r','nobs_z']\n",
    "        writer = csv.DictWriter(oFile, fieldnames=oFields)    \n",
    "        writer.writeheader()\n",
    "        for o in objects:\n",
    "            writer.writerow({'brickname':o['brickname'],'objid':o['objid'],'filename':o['filename'],'ra':o['ra'],'dec':o['dec'],'flux_g':o['flux_g'],'flux_r':o['flux_r'],'flux_z':o['flux_z'],'mag_g':o['mag_g'],'mag_r':o['mag_r'],'mag_z':o['mag_z'],'nobs_g':o['nobs_g'],'nobs_r':o['nobs_r'],'nobs_z':o['nobs_z']})\n",
    "    \n",
    "    print('done.')\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = download_Tractor2(csvfile='classifications', objectcsvfile='objectinfo', t_folder='000', n_objects=150, min_passes=4, counter_init=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is for Chris to use on CMU DeepLens\n",
    "\n",
    "# opens csv file made in download_Tractor, also uses object dictionary from the above cell to create an hdf5 file with\n",
    "# the csv info and image array\n",
    "def make_hdf5(csvfile, objects, imgs):\n",
    "    # imgs = number of images to write\n",
    "    cat = Table.read(csvfile)\n",
    "    if imgs < len(cat):\n",
    "        cat= cat[0:imgs]\n",
    "    ims = np.zeros((imgs, 3, 101, 101)) # 4 -> 3\n",
    "   \n",
    "    # Loads the images from object dictionaries (previous cell)\n",
    "    for o in objects:\n",
    "        ims[i] = o['image']\n",
    "\n",
    "    # Concatenate images to catalog\n",
    "    cat['image'] = ims\n",
    "\n",
    "    # Export catalog as HDF5 (should probably include path before 'catalogs_')\n",
    "    cat.write('catalogs_'+str(imgs)+'.hdf5', path='/ground', append=True)\n",
    "\n",
    "    ###### THIS MAY HAVE TO GO SOMEWHERE ELSE\n",
    "    from astropy.table import Table\n",
    "    # Loads the table created in the previous section\n",
    "    d = Table.read(export_path+'catalogs_'+str(imgs)+'.hdf5', path='/ground') # Path to be adjusted on your machine\n",
    "    x = array(d['image']).reshape((-1,3,101,101)) # 4 -> 3\n",
    "    print x.shape\n",
    "    y = array(d['is_lens']).reshape((-1,1))\n",
    "    print y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also, in order to run this code on other computers, tractor_folders/, tractor_fits/, and fits_cutouts/ must be created and their paths added to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just plotting images\n",
    "for i in range(len(test)):\n",
    "    image = test[i]['image']\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.subplot(131)\n",
    "    plt.title('IMAGES FOR OBJECT AT RA={}, DEC={}'.format(test[i]['ra'], test[i]['dec']))\n",
    "    plt.imshow(image[0,:,:])\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(image[1,:,:])\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(image[2,:,:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    image = test[i]['image']\n",
    "    plt.imshow(image.T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
